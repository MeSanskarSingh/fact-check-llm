{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002c9b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roopa\\miniconda3\\envs\\agentic\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436c1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model = ChatMistralAI(\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eec780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Claim(BaseModel):\n",
    "    claim: str = Field(description=\"Original extracted factual statement exactly as inferred from rumor\")\n",
    "    claim_type: str = Field(description=\"One of: health | death | policy | event | statistic | relationship | other\")\n",
    "    entities: list[str] = Field(description=\"Primary real-world named entities only (people, substances, diseases, organizations, places)\")\n",
    "    time: str = Field(description=\"Explicit time reference or NAN\")\n",
    "    location: str = Field(description=\"Explicit location reference or NAN\")\n",
    "    canonical_text: str = Field(description=(\n",
    "            \"Normalized factual sentence following strict grammar rules:\\n\"\n",
    "            \"Format: <subject> <relation> <object> [context]\\n\\n\"\n",
    "\n",
    "            \"Allowed relation verbs:\\n\"\n",
    "            \"prevents | causes | cures | treats | increases | decreases | kills | contains | \"\n",
    "            \"leads_to | results_in | died_from | implemented | occurred_in | affects\\n\\n\"\n",
    "\n",
    "            \"Rules:\\n\"\n",
    "            \"- lower case except proper nouns\\n\"\n",
    "            \"- no adjectives or emotional words\\n\"\n",
    "            \"- no modal verbs: may, might, can, possibly, reportedly, allegedly\\n\"\n",
    "            \"- no explanations or extra sentences\\n\"\n",
    "            \"- maximum 12 words\\n\"\n",
    "            \"- must describe real-world effect, not belief\\n\"\n",
    "            \"- medical claims must end with 'in humans' when about health\\n\"\n",
    "        )\n",
    "    )\n",
    "class RumorSchema(BaseModel):\n",
    "    claims: list[Claim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dad013",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(RumorSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an information extraction system.\n",
    "\n",
    "Given a rumor, extract independent factual claims and produce a normalized canonical statement.\n",
    "\n",
    "IMPORTANT:\n",
    "The canonical_text is NOT a paraphrase.\n",
    "It is a controlled factual identity sentence used for semantic matching.\n",
    "\n",
    "GENERAL RULES:\n",
    "- Each claim must be independently verifiable true or false\n",
    "- Extract implied claims\n",
    "- Do NOT merge multiple facts\n",
    "- No explanations\n",
    "- Return STRICT JSON only\n",
    "- If time/location missing return NAN\n",
    "\n",
    "CANONICAL TEXT GRAMMAR:\n",
    "Write a single sentence using:\n",
    "\n",
    "<subject> <relation_verb> <object> [context]\n",
    "\n",
    "Allowed relation verbs:\n",
    "prevents | causes | cures | treats | increases | decreases | kills | contains |\n",
    "leads_to | results_in | died_from | implemented | occurred_in | affects\n",
    "\n",
    "CONSTRAINTS:\n",
    "- lowercase except proper nouns\n",
    "- remove words like: may, might, can, possibly, reportedly, secret, shocking\n",
    "- no adjectives\n",
    "- â‰¤ 12 words\n",
    "- health claims must end with \"in humans\"\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "Rumor: \"haldi cures corona instantly\"\n",
    "Output canonical_text: \"turmeric cures COVID-19 infection in humans\"\n",
    "\n",
    "Rumor: \"5g towers spread covid\"\n",
    "Output canonical_text: \"5G towers cause COVID-19 infection in humans\"\n",
    "\n",
    "Rumor: \"government secretly added microchips in vaccines\"\n",
    "Output canonical_text: \"vaccines contain microchips\"\n",
    "\n",
    "Schema:\n",
    "claims: [\n",
    "    {{\n",
    "        claim: string\n",
    "        claim_type: string\n",
    "        entities: list[string]\n",
    "        time: string\n",
    "        location: string\n",
    "        canonical_text: string\n",
    "    }}\n",
    "]\n",
    "\n",
    "Rumor: {rumor}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b431f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims=[Claim(claim='doctors say drinking cold water after meals causes stomach cancer', claim_type='health', entities=['doctors'], time='NAN', location='NAN'), Claim(claim='the claim is spread from whatsapp', claim_type='other', entities=['whatsapp'], time='NAN', location='NAN'), Claim(claim='the claim is about India', claim_type='other', entities=['India'], time='NAN', location='India')]\n",
      "{'claims': [{'claim': 'doctors say drinking cold water after meals causes stomach cancer', 'claim_type': 'health', 'entities': ['doctors'], 'time': 'NAN', 'location': 'NAN'}, {'claim': 'the claim is spread from whatsapp', 'claim_type': 'other', 'entities': ['whatsapp'], 'time': 'NAN', 'location': 'NAN'}, {'claim': 'the claim is about India', 'claim_type': 'other', 'entities': ['India'], 'time': 'NAN', 'location': 'India'}]}\n",
      "<class '__main__.RumorSchema'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"rumor\": \"From whatsapp doctors say drinking cold water after meals causes stomach cancer in India\"\n",
    "})\n",
    "print(result)\n",
    "print(result.model_dump())\n",
    "print(type(result))\n",
    "print(type(result.model_dump()))\n",
    "#have to return result.model_dump() as dict and convert to json by json.loads(dict)function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
